- try fitting with n_atom_select = 15 and n_mol_select = 40

data setup:
exp_all_1: naf = 20, t = 586.5640139000001s
exp_all_2: naf = 20, t = 10536.0200658s


$OMP1:
julia> testtimeactual("exp_all_1", 10_000)                                              
[Nqm9, N, nK, nf, ns, nL] = [133628, 300, 100, 28, 5, 140]                              
linop timings [t_ax, t_atv] = [0.319343393, 1.065184946], total = 1.384528339           
[intermediate values, batchpred of VK(w_m) ∀m ∈ Nqm9] = [0.223031794, 185.475802537]

$SAINT:
julia> testtimeactual("exp_all_1", 2223)
[Nqm9, N, nK, nf, ns, nL] = [133628.0, 300.0, 100.0, 28.0, 5.0, 140.0]
linop timings [t_ax, t_atv] = [0.3374591, 0.5015092], total = 0.8389683
[intermediate values, batchpred of VK(w_m) ∀m ∈ Nqm9] = [0.199886, 75.3966083]

julia> testtimeactual("exp_all_2", 5_000)
[Nqm9, N, nK, nf, ns, nL] = [133628.0, 2400.0, 100.0, 120.0, 15.0, 1800.0]
linop timings [t_ax, t_atv] = [13.2890423, 76.2501555], total = 89.53919780000001
[intermediate values, batchpred of VK(w_m) ∀m ∈ Nqm9] = [36.992655, 1190.335657]

Nqm9	nK	nU	nf	ns	MAE	||Aθ-b||^2	max(MAD(U))	use_MAD	t_inter	t_solver	t_pred  machine
133628.0	100.0	200.0	28.0	5.0	3.04453346e+04	2.53093305e+00	1.07627011e-02	false	0.292552525	603.838726578	95.438554876    OMP1
133628.0	100.0	2300.0	120.0	15.0	2.76078121e+04	6.11409172e+02	1.20520404e-01	false	37.230703	974.5096926	1190.1894936    SAINT

try: 
{4, 5, 6} n_af using corr matrix (instead of cov matrix) for the sums only, and try with the rest of the features from the best n_af (also the eigenvalues plots).

SOAP extraction time = 524.7424840927124 s
Filesize = 6GB
feature length = 1950
SOAP data setup: 1274s

implement kernel ridge regression from FCHL18

02.12.2022:
- retry the sigma comptation using only 500 x 100 data, and also store the norms, and the sigma must give a nice number (rounded, but sigma0 is fine to be floating point)
- try using the atomic features formula instead of the molecular features
- put the timing and storage to the pdf

05.12.2022:
- the MAE of QM9 doesn't match with lilienfields' paper??

05.12.2022:
- mol gaussian: 1800, atomic PCA by MAE -> mol PCA standard : 2239.269684670436
- RoSeMI: 1700
- NN (with architecture similar to ACSF paper), lowest = 1000
atomic gaussian:
- sum = 40588
- mean = 23911
- mean full feature (no PCA) = 25039
- mean scaled by MAE = 22229

06.12.2022:
Improving the feature quality:
- compute the MAE := max(|\delta f|)/N, this is the sensitivity
- compute the covariance from actual f (store for multiple usage), divide using sensitivity as the diagonals

12.12.2022:
3.42 kcal/mol schnet w/ 1k training 500 eval
14.3 kcal/mol 100 train

14.12.2022:
23 kcal/mol 100 train with just atomcount as features, with linear leastsquares solver, more details:
  L1: 23.4
  L2: 23.3
  K1: 540.08
  K2: 540.04
23.8 kcal/mol: fit atomref w/ 100 E -> use reduced E for ROSEMi fit with 100 E.

! refit the shepard model:
* using 100 points obtained from L1 (do not recompute!!)
* E[Midx] -= EL1[Midx]
* predict using the model trained from the E[all\Midx] += EL1[all\Midx] to the prediction
* compute error, the error should be reduced

! do loop exp:
* LLS using training energies from ROSEMI's features:
  - record the atomic reference energies (the thetas := [E_H, E_C, E_N, E_O, E_F]) (*)
* Refit ROSEMI (or any other models) using the reference energies:
  - compute the mean absolute value of E_red := E_l - A*theta, or E_l - n_a*theta_a, (*)
  - compute MAE of ROSEMI fitted using reduced energy: predict the E_red of all QM9 then add E_pred = E_red + n_a*theta_a (*)
(*) means record the values

15.12.2022:
atomref info, MAE in kcal/mol while the rest are in Hartree:

	MAE	E_H	E_C	E_N	E_O	E_F
	21.2	-0.6	-38.07	-54.74	-75.22	-99.86

fitting info, MAE in kcal/mol:

	model MAE nK  nU	n_af	n_mf	n_basis	
	ROSEMI	23.7  100 200	4	18	5	
  KRR	21.3  100 200	4	18	5	
  NN	21.1  100 200	4	18	5	
  LLS	19.4  100 200	4	18	5	

16.12.2022:
- try: http://www.qmlcode.org/tutorial.html for FCHL feature

29.12.2022:
FCHL:
- 100 train: 257 kcal/mol
- 100 train center: 129 kcal/mol
- 100 train center & reduced energy: 9.33706302295949 kcal/molecular
batchpred t =  3849s for SAINT
batchpred t = 11448s for OMP1

03.01.2023:
not possible to implement FCHL Kernel in Julia, the python & fortran code is not 1:1 to the formula and is way too complicated,
alternative: call py from Julia

04.01.2023:
FCHL contains edge features, so the treatment should be different (look at the fortran code)

10.01.2023:
inject fortran code: get from github, edit the .f90 files, "pip install ." in the directory, no need to uninstall if there's any change, just do pip install again

16.01.2023:
ACSF, gaussian atom kernel w/ kronecker delta (without preprocessing the features), direct solve = 37 kcal/mol, CGLS = 22.7 kcal/mol, t_pred = 907s
 ====        w/o kronecker delta, CGLS =  29.9, t_pred= 2356s
SOAP, GAK, w/ kronecker delta, CGLS = 20.5 kcal/mol
SOAP, GAL, w/ kron, preproc data, 17.5 kcal/mol

19.01.2023:
- for each experiment, "GC.gc()" garbage collector is necessary, such that it doesnt explode the ram
! fix the Julia version, different Julia version gives different eigenvectors, the fitting result of OMP1 and SAINT is different!
- to use random seed: call the seed before each random s.t. the numbers are reproducible
- do experiments with different sets of K (see paper)

24.01.2023:
- usequence experiment: uniformly distributed data especially [0,1], gives the same selected points, even on lower dimensions

01.02.2023:
- FCHL atom: removed 5 features since they give no covariance -> 140 length atomic features
- Start the hyperparameter tuning with Morteza's DFO

03.02.2023:
- for the atomic fitting, the test MAE must not be used !! (since we can only use 100 energies). Only take from the training MAE. => recompute the atomic fitting, save the training MAE
- fitting needs to be slower than the hyperopt (and needs delay)

15.02.2023:
varlist that must be emptied on each experiment run:
  alouet:
    data_setup: dataset=F=f=ϕ=dϕ=centers=redf=nothing
    fit_rose_and_atom: dataset = E_dict = f = F = ϕ = dϕ = E = D = E_atom = Midx = Uidx = Widx = nothing
    fit_atom: dataset=F_atom=E=center_ids=Midx=Widx=A=θ=stat=errors=E_pred=E_atom=E_red_mean=Ed=nothing
    ROSEMI fitter: SKs_train = SKs = γ = α = B = klidx = cidx = Axtemp = tempsA = op = b = tempsb = θ = stat = VK = outs = v = vmat = MADs = batches = VK_fin = nothing
    KRR fitter: Norms=K=θ=stat=errors=K_pred=E_pred=Er=nothing
    NN fitter: x_train=model=pars=opt=nothing
    LLS fitter: A=θ=stat=errors=E_pred=nothing
    GAK fitter: A=θ=stat=E_pred=errors=nothing

  linastic:
    PCA_atom: s = ∑ = C = D = e = nothing
    PCA_atom: C = e = F = nothing

22.02.2023:
- need to change paramcheck into parambound
- save list of (f,x) using the driver.m instead of jl

03.03.2023:
- use midpoint for initialization: change Inf bounds.

06.03.2023:
- try removing 3k dataset (the "defective" datasets)
- try regularization in CGLS (add lambda, possibly a new hyperparameter)

08.03.2023:
- revert back main in expdriver to previous one (non-translator mode)
- new projection, rounding, and translation mode, in matlab file

14.03.2023:
- try experiments with S := 1/(N-1).... instead of 1/N, it adds regularization effect
- round the atomic energies to integers before use for experiments, since the mean of the rounding error is around 1.5 while the std has larger error (this will change the things slightly).

04.04.2023:
- table of collection of hyperparameters checkpoint in "data/hyperparamopt/tables/tf_fsort.txt"
- separate mintry(x,f) and decoder(x), useful for "infeasible" initial point

14.04.2023:
- tried empirical cumulative distribution function (ECDF) for feature binning, seems like for atom (GAK), binning full data gives better MAE; not yet tested for molecules (MGK/KRR, LLS, NN, etc).

17.04.2023:
- tested FCHL Kernel with center index = 38 as training set, MAE = 7.088911846921814
- for now removed FCHL atomic feature from hyperparameteropt, since it causes NaN; changed c to int instead of real
- changed init params, following the bounds, now the vector size is 16
- all_tb_170423 contains all of the current found hyperparameters 

19.04.2023:
- Hyperparams which are possible to improve MATRs:
  + inittune.m: cdeltamin [30]
  + inittune.m: cnu [21]
  + in general larger budget gives better result, recommended = 1200*n (current, n=16 -> 19200 nfmax)
- changed penalty factor to 10, see if this gives better results
- init tuning using best hyperparameter with MAE=11.62 (see caller_pc.m)

25.04.2023:
- repker w/ CGLS w/ current "best" feature: (train, test, machine) = (13.315580220029185, 18.506755171167082, SAINT) 
? the mol PCA gives different results in SAINT and OMP1 but atom PCA is the same ???, reproduce result: data_setup("exp_reduced_energy", 20, 16, 5, 300, "data/qm9_dataset_old.jld", "data/ACSF.jld", "ACSF"; save_global_centers = false)
found the reason: cor() gives different result between SAINT and OMP1!!, turns out looks like this is accumulated from small error difference accross large data, atom gives the same eigen but some small error accumulated -> different mol features, surely the MAE is not much different?
turns out the MAE is completely different, maybe next directly compare the atom eigenvectors?
turns out the difference is all the way from the eigen atom, small numerical difference snowballs until the mol computation

26.04.2023:
- repker as feature generated from 20-16 with centers as col: (train, test, machine) = (12.503066223772425, 18.68415919418044, OMP1)
- repker atom level from 20-16: 
  ! (train, test, mode, machine) = (7.828382458724014, 10.998833688919287, CGLS, OMP1), current best! 
  ! (train, test, mode, machine) = (7.989517036864852, 11.043965907343884, CGLS, SAINT), really need to check the difference of numresults between SAINT and OMP1 (bug)!
- try parallel mode of hyperparameter optimization (need VSC access):
  1 init as usual
  2 perturb the next iterate into n different iterates, broadcast this to slaves
  3 get the best iterates from the slaves into master
  4 go to 2
- implement message passing (see paper and its writtings)

03.05.2023:
- test MP without sigma yet, (t, data, train, test, model, machine):
  - (1, ACSF, 8.531877790679385, 13.637190148167665, REAPER, SAINT)
  - (5, ACSF, 12.134951800081835, 19.285999493686106, REAPER, SAINT)
  - (1, 20--16, 6.405897394503283, 13.164806953612652, REAPER, SAINT)
  - (2, 20--16, 6.027474617840749, 13.895430026759396, REAPER, SAINT)
- test MP without PCA:
  - (1, ACSF, 7.687329449835585, 12.792789108425062, REAPER, SAINT)
  - (2, ACSF, 7.9554008405230405, 13.032915591258527, REAPER, SAINT)
  - (1, 20--16, 7.700348168196548, 13.380650010040405, REAPER, SAINT)
  - (2, 20--16, 8.115258754956065, 12.977283254952756, REAPER, SAINT)
  ...
- see paper(s) for hyperoptparallelization.
  
05.05.2023:
- the parallelization will probably be in slurm level:
  First scheme of parallelizatgion:
  - 3 big processes, 2 masters (mintry m, controller jl), and 1 slave category (n simulators jl)
  - mintry and simulators run as usual, controller controls the (x,f) flow, spawn processes, etc
  Or:
  - 3 processes: mintry.m, controller.jl/m, generator.m, simulators.jl
  - mintry: as usual, runs indefinitely, reads mintry table periodically -- get (x,f) pair, compute x = mintry(x,f), store x in mintry table 
  - controller runs indefinitely, reads sim table periodically, if sufficient numbers of data depending on id is accumulated, store best(f) in mintry table  
  - generator runs indefinitely, reads new signals from the simulators periodically, get x from mintry's table, returns xhat = perturb(xraw) for each new signal 
  - simulators: run indefenitely, asks for new xhat if idle (sends signal to generator), compute f = f(xhat), store f to sim table ({id,f,x,})
  - see paper for more details.
- the simulators can be in slurm level (node level) (recommended, since each proc \in node), the number of processes run in this case can be determined by running in jl:
    s = readchomp(`squeue -u berylaribowo`) # to read the output of command
    ...
    count the occurence of job containing "..jl" as job name identifier
- the main processors should only be: mintry, controller, simulators. Controller bridges the mintry and simulator, mintry and simulator work as usual

15.05.2023:
- (see paper) need to accomodate for when:
  - disjoint iteration: 1 -> 3. Sol? add iter_id
  - n_sim idle > thresh OR n_sim run < thresh => thresh not fulfilled => no f update for mintry => no x update from mintry => all sim idle (no iter update). Sol? put sim_state

17.05.2023:
- fobj listener is now only depends on the iter -> any simulator can compute any iterations
- iter tracker now is more simple.
- speed: simulator listener > controller listener > mintry listener, since it's possible that the simulator receive duplicate x if the simulator is too slow on receiveing signal

22.05.2023:
Quests:
? avoid controller giving multiple generated-x if simulator's listener is slower => make controller (listener) speed < simulator speed
? handle case where if there is no new f accepted AND no new x given (no running sim, no update from mintry) =>  accpet whatever f is in the contr repo, but if repo is empty??? -> stuck, iter doesnt advance.
? when not enough new iterates, 2 choices:
  - don't anything to sim -> (see quest 2)
  - (choose dis) give whatever x, sim MUST NOT compute f(x) but looks into the repo and returns f -> this needs one (x,f(x)) repository, race condition since one sim accesses the same file?? -> race condition is fine, doesnt give any error!
? write simulator (jl), algo:
  - initialize simulator with only "state = idle" f info
  - listen to controller's signal (faster than controller), read x file: 
    - set state = running
    - if uid is different, check x: 
      - if x exists in tracker: write the corresponding f. Otherwise: run f = f(x) and write f, 
    - set state = idle

08.06.2023:
- reproduced delta ML testing from QML tutorial
- reproduced kernel result of Python QML in julia, by using the direct solve and regularizer, the result is exactly the same.
? see Unit Testing of Julia for more comprehensive unit tests
? for more threading parallelization: see https://levelup.gitconnected.com/parallel-code-in-julia-with-threads-b2e7c97f071b

12.06.2023:
- tried naive pairpot as base energy, turns out to be worse than standard ML, probably need to tune the hyperparameters (alpha, delta, set their dependencies, etc)

13.06.2023:
! maybe try triplet features
! check out SLATM representation (maybe doesnt require specialized kernel)
  checked SLATM, turns out it has 17895 features! (very large), around 22gb for all qm9 data
- added overleaf shared with prof.lilienfeld

14.06.2023:
- slaves can be spawned as much as possible in the VSC
! try separating simulator output files for parallel hyperparam
! test using actual fobj
! add automatic "garbage" remover (reset files to empty) || 1
! need to add automatic simulator spawner

19.06.2023:
- get_prop(mol, n1, n2, :order) gives the bond order from MolecularGraph (see dp.jl).

20.06.2023:
- Ebase = Enull + Esob for LLS model gives ~6kcal/mol accuracy reduction, BUT for the prev best found model turns out this overfits, train = 1e-12 but test is 1e+2

21.06.23:
! for math desc of aSLATM and FCHL18 look at https://github.com/lcmd-epfl/intro-to-qml/blob/master/Introduction%20to%20QML.ipynb.
! try to get the FCHL19 first, simpler representation.
! see qmml.org for preprocessed qm9 dataset and probably usew it

26.06.23:
- nRs2 = 12, nRs3 = 10, rcut = 6˚A and nmax = lmax = 3, σ = 0.1, rcut = 6˚A (for fchl19 and aSLATM respectively from mbdf paper)

28.06.23:
(DONE) ! recompute features for dressed atoms := null, and features for dressed bonds, using new full set of data
(DONE) using dscribe ? index 184 cause error for QML's ACSF, use dscribe or the ol julia acsf instead

30.06.23:
- can use MolecularGraph's neighbors(atom) to get the triplet (probably for angle?)

04.07.23:
- check ACSF: kernels (GAK, repker) gave NaNs
- check whether i can get extra disk space for VSC

06.07.23:
- ThreadsX works well! especially on VSC, now computation is blazing fast!, other functions should be chagned to ThreadsX

07.07.23:
- std matrix threadsx gives an error, correct later

19.07.23:
! less file OP for faster speed for data_setup and fitter

20.07.23:
- difference in index and E between saint and vsc due to randomness
- fileOP is still confusing for the deltaML, fix later

26.07.23:
- C(n_neighbors, 2) = number of angles exist in a partition of n_atoms when observing a center atom.
- for torsion, probably we can observe an edge, and see neighbours(src(e)) union neighbors(dst(e)) \ dst(e) union src(e)
! finish get angle then get angle type

02.08.23:
- try PCA or manual feature selection (removing some types of angles) for dressed angle.

04.08.23:
- add manual readme for hyperparamopt parallel usage, often forgot how to use it.
- need to change some hyperparam boundaries (due to changing hyperparamopt)

08.08.23:
- trial of built in Julia PCA
- maybe try PCA bond energies too?
! think of the getting the torsion algorithm