- try fitting with n_atom_select = 15 and n_mol_select = 40

data setup:
exp_all_1: naf = 20, t = 586.5640139000001s
exp_all_2: naf = 20, t = 10536.0200658s


$OMP1:
julia> testtimeactual("exp_all_1", 10_000)                                              
[Nqm9, N, nK, nf, ns, nL] = [133628, 300, 100, 28, 5, 140]                              
linop timings [t_ax, t_atv] = [0.319343393, 1.065184946], total = 1.384528339           
[intermediate values, batchpred of VK(w_m) ∀m ∈ Nqm9] = [0.223031794, 185.475802537]

$SAINT:
julia> testtimeactual("exp_all_1", 2223)
[Nqm9, N, nK, nf, ns, nL] = [133628.0, 300.0, 100.0, 28.0, 5.0, 140.0]
linop timings [t_ax, t_atv] = [0.3374591, 0.5015092], total = 0.8389683
[intermediate values, batchpred of VK(w_m) ∀m ∈ Nqm9] = [0.199886, 75.3966083]

julia> testtimeactual("exp_all_2", 5_000)
[Nqm9, N, nK, nf, ns, nL] = [133628.0, 2400.0, 100.0, 120.0, 15.0, 1800.0]
linop timings [t_ax, t_atv] = [13.2890423, 76.2501555], total = 89.53919780000001
[intermediate values, batchpred of VK(w_m) ∀m ∈ Nqm9] = [36.992655, 1190.335657]

Nqm9	nK	nU	nf	ns	MAE	||Aθ-b||^2	max(MAD(U))	use_MAD	t_inter	t_solver	t_pred  machine
133628.0	100.0	200.0	28.0	5.0	3.04453346e+04	2.53093305e+00	1.07627011e-02	false	0.292552525	603.838726578	95.438554876    OMP1
133628.0	100.0	2300.0	120.0	15.0	2.76078121e+04	6.11409172e+02	1.20520404e-01	false	37.230703	974.5096926	1190.1894936    SAINT

try: 
{4, 5, 6} n_af using corr matrix (instead of cov matrix) for the sums only, and try with the rest of the features from the best n_af (also the eigenvalues plots).

SOAP extraction time = 524.7424840927124 s
Filesize = 6GB
feature length = 1950
SOAP data setup: 1274s

implement kernel ridge regression from FCHL18

02.12.2022:
- retry the sigma comptation using only 500 x 100 data, and also store the norms, and the sigma must give a nice number (rounded, but sigma0 is fine to be floating point)
- try using the atomic features formula instead of the molecular features
- put the timing and storage to the pdf

05.12.2022:
- the MAE of QM9 doesn't match with lilienfields' paper??

05.12.2022:
- mol gaussian: 1800, atomic PCA by MAE -> mol PCA standard : 2239.269684670436
- RoSeMI: 1700
- NN (with architecture similar to ACSF paper), lowest = 1000
atomic gaussian:
- sum = 40588
- mean = 23911
- mean full feature (no PCA) = 25039
- mean scaled by MAE = 22229

06.12.2022:
Improving the feature quality:
- compute the MAE := max(|\delta f|)/N, this is the sensitivity
- compute the covariance from actual f (store for multiple usage), divide using sensitivity as the diagonals

12.12.2022:
3.42 kcal/mol schnet w/ 1k training 500 eval
14.3 kcal/mol 100 train

14.12.2022:
23 kcal/mol 100 train with just atomcount as features, with linear leastsquares solver, more details:
  L1: 23.4
  L2: 23.3
  K1: 540.08
  K2: 540.04
23.8 kcal/mol: fit atomref w/ 100 E -> use reduced E for ROSEMi fit with 100 E.

! refit the shepard model:
* using 100 points obtained from L1 (do not recompute!!)
* E[Midx] -= EL1[Midx]
* predict using the model trained from the E[all\Midx] += EL1[all\Midx] to the prediction
* compute error, the error should be reduced

! do loop exp:
* LLS using training energies from ROSEMI's features:
  - record the atomic reference energies (the thetas := [E_H, E_C, E_N, E_O, E_F]) (*)
* Refit ROSEMI (or any other models) using the reference energies:
  - compute the mean absolute value of E_red := E_l - A*theta, or E_l - n_a*theta_a, (*)
  - compute MAE of ROSEMI fitted using reduced energy: predict the E_red of all QM9 then add E_pred = E_red + n_a*theta_a (*)
(*) means record the values

15.12.2022:
atomref info, MAE in kcal/mol while the rest are in Hartree:

	MAE	E_H	E_C	E_N	E_O	E_F
	21.2	-0.6	-38.07	-54.74	-75.22	-99.86

fitting info, MAE in kcal/mol:

	model MAE nK  nU	n_af	n_mf	n_basis	
	ROSEMI	23.7  100 200	4	18	5	
  KRR	21.3  100 200	4	18	5	
  NN	21.1  100 200	4	18	5	
  LLS	19.4  100 200	4	18	5	

16.12.2022:
- try: http://www.qmlcode.org/tutorial.html for FCHL feature

29.12.2022:
FCHL:
- 100 train: 257 kcal/mol
- 100 train center: 129 kcal/mol
- 100 train center & reduced energy: 9.33706302295949 kcal/molecular
batchpred t =  3849s for SAINT
batchpred t = 11448s for OMP1

03.01.2023:
not possible to implement FCHL Kernel in Julia, the python & fortran code is not 1:1 to the formula and is way too complicated,
alternative: call py from Julia

04.01.2023:
FCHL contains edge features, so the treatment should be different (look at the fortran code)

10.01.2023:
inject fortran code: get from github, edit the .f90 files, "pip install ." in the directory, no need to uninstall if there's any change, just do pip install again

16.01.2023:
ACSF, gaussian atom kernel w/ kronecker delta (without preprocessing the features), direct solve = 37 kcal/mol, CGLS = 22.7 kcal/mol, t_pred = 907s
 ====        w/o kronecker delta, CGLS =  29.9, t_pred= 2356s
SOAP, GAK, w/ kronecker delta, CGLS = 20.5 kcal/mol
SOAP, GAL, w/ kron, preproc data, 17.5 kcal/mol

19.01.2023:
- for each experiment, "GC.gc()" garbage collector is necessary, such that it doesnt explode the ram
! fix the Julia version, different Julia version gives different eigenvectors, the fitting result of OMP1 and SAINT is different!
- to use random seed: call the seed before each random s.t. the numbers are reproducible
- do experiments with different sets of K (see paper)

24.01.2023:
- usequence experiment: uniformly distributed data especially [0,1], gives the same selected points, even on lower dimensions

01.02.2023:
- FCHL atom: removed 5 features since they give no covariance -> 140 length atomic features
- Start the hyperparameter tuning with Morteza's DFO

03.02.2023:
- for the atomic fitting, the test MAE must not be used !! (since we can only use 100 energies). Only take from the training MAE. => recompute the atomic fitting, save the training MAE
- fitting needs to be slower than the hyperopt (and needs delay)

15.02.2023:
varlist that must be emptied on each experiment run:
  alouet:
    data_setup: dataset=F=f=ϕ=dϕ=centers=redf=nothing
    fit_rose_and_atom: dataset = E_dict = f = F = ϕ = dϕ = E = D = E_atom = Midx = Uidx = Widx = nothing
    fit_atom: dataset=F_atom=E=center_ids=Midx=Widx=A=θ=stat=errors=E_pred=E_atom=E_red_mean=Ed=nothing
    ROSEMI fitter: SKs_train = SKs = γ = α = B = klidx = cidx = Axtemp = tempsA = op = b = tempsb = θ = stat = VK = outs = v = vmat = MADs = batches = VK_fin = nothing
    KRR fitter: Norms=K=θ=stat=errors=K_pred=E_pred=Er=nothing
    NN fitter: x_train=model=pars=opt=nothing
    LLS fitter: A=θ=stat=errors=E_pred=nothing
    GAK fitter: A=θ=stat=E_pred=errors=nothing

  linastic:
    PCA_atom: s = ∑ = C = D = e = nothing
    PCA_atom: C = e = F = nothing

22.02.2023:
- need to change paramcheck into parambound
- save list of (f,x) using the driver.m instead of jl

03.03.2023:
- use midpoint for initialization: change Inf bounds.

06.03.2023:
- try removing 3k dataset (the "defective" datasets)
- try regularization in CGLS (add lambda, possibly a new hyperparameter)

08.03.2023:
- revert back main in expdriver to previous one (non-translator mode)
- new projection, rounding, and translation mode, in matlab file

14.03.2023:
- try experiments with S := 1/(N-1).... instead of 1/N, it adds regularization effect
- round the atomic energies to integers before use for experiments, since the mean of the rounding error is around 1.5 while the std has larger error (this will change the things slightly).

04.04.2023:
- table of collection of hyperparameters checkpoint in "data/hyperparamopt/tables/tf_fsort.txt"
- separate mintry(x,f) and decoder(x), useful for "infeasible" initial point

14.04.2023:
- tried empirical cumulative distribution function (ECDF) for feature binning, seems like for atom (GAK), binning full data gives better MAE; not yet tested for molecules (MGK/KRR, LLS, NN, etc).

17.04.2023:
- tested FCHL Kernel with center index = 38 as training set, MAE = 7.088911846921814
- for now removed FCHL atomic feature from hyperparameteropt, since it causes NaN; changed c to int instead of real
- changed init params, following the bounds, now the vector size is 16
- all_tb_170423 contains all of the current found hyperparameters 

19.04.2023:
- Hyperparams which are possible to improve MATRs:
  + inittune.m: cdeltamin [30]
  + inittune.m: cnu [21]
  + in general larger budget gives better result, recommended = 1200*n (current, n=16 -> 19200 nfmax)
- changed penalty factor to 10, see if this gives better results
- init tuning using best hyperparameter with MAE=11.62 (see caller_pc.m)

25.04.2023:
- repker w/ CGLS w/ current "best" feature: (train, test, machine) = (13.315580220029185, 18.506755171167082, SAINT) 
? the mol PCA gives different results in SAINT and OMP1 but atom PCA is the same ???, reproduce result: data_setup("exp_reduced_energy", 20, 16, 5, 300, "data/qm9_dataset_old.jld", "data/ACSF.jld", "ACSF"; save_global_centers = false)
found the reason: cor() gives different result between SAINT and OMP1!!, turns out looks like this is accumulated from small error difference accross large data, atom gives the same eigen but some small error accumulated -> different mol features, surely the MAE is not much different?
turns out the MAE is completely different, maybe next directly compare the atom eigenvectors?
turns out the difference is all the way from the eigen atom, small numerical difference snowballs until the mol computation

26.04.2023:
- repker as feature generated from 20-16 with centers as col: (train, test, machine) = (12.503066223772425, 18.68415919418044, OMP1)
- repker atom level from 20-16: 
  ! (train, test, mode, machine) = (7.828382458724014, 10.998833688919287, CGLS, OMP1), current best! 
  ! (train, test, mode, machine) = (7.989517036864852, 11.043965907343884, CGLS, SAINT), really need to check the difference of numresults between SAINT and OMP1 (bug)!